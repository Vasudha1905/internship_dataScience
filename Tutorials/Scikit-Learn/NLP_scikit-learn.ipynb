{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda6d3be-300b-4b78-84b1-829166f3ea17",
   "metadata": {},
   "source": [
    "## Scikit-Learn Tutorial\n",
    "### Natural Language Processing(NLP) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a759f-ae3f-48b5-8550-001d53dee976",
   "metadata": {},
   "source": [
    "#### eliminating punctuation and stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48f90e9-9824-45cc-8746-d225ac7af5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0acde6cc-c94c-4382-a948-6fc634dde87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first 10 stopwords \n",
    "stopwords.words('english')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5476af78-6a6f-4f8e-a597-0c2c70a14321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test sentence\n",
    "test_sentence = 'This is my first string. Wow! we are doing just fine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a03d4bb-b50c-40b6-8233-0c9d68248e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate the punctuation\n",
    "no_punctuation = [c for c in test_sentence if c not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99929236-4e1a-4510-8b75-ae26a9404f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is my first string Wow we are doing just fine'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_punctuation = ''.join(no_punctuation)\n",
    "no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6af3633-c681-453c-b0cf-5686ef540ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first', 'string', 'Wow', 'fine']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminate stopwords\n",
    "clean_sentence = [word for word in no_punctuation.split() if word.lower() not in stopwords.words('english')]\n",
    "clean_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d12a8f8-2c8e-438c-b4be-595bd89bb0d7",
   "metadata": {},
   "source": [
    "#### bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be1c40ad-9976-4f5a-bc0e-63376fed3fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0fbe6c-b1c7-4a30-8f1b-367f4f33510f",
   "metadata": {},
   "source": [
    "*  transform text data into numerical data \n",
    "* It counts how many times each word appears in each document.\n",
    "*  The output is a matrix where rows are documents and columns are words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b37b4d61-2aa4-4160-a362-a4fbf8608c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4f0dbdd-b38d-4b6c-9acb-9853a7094475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3 documents\n",
    "doc1 = \"This is first document\"\n",
    "doc2 = \"This is second document\"\n",
    "doc3 = \"This is third document\"\n",
    "listofdocument=[doc1,doc2,doc3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f30914e-dabf-4668-81d8-160315f3382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit\n",
    "bag_of_words = vectorizer.fit(listofdocument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "204a5078-a7f0-4a5a-bb88-6eda1eb9ea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 5)\t1\n"
     ]
    }
   ],
   "source": [
    "# apply transform method\n",
    "bag_of_words = vectorizer.transform(listofdocument)\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea7a50c-b129-4f0d-b26e-484ee53d643c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
